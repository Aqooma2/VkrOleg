{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kTFrNNPU7wP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yu50xj5jU8I6"
   },
   "outputs": [],
   "source": [
    "train_ds = pd.read_csv(\"train.csv\")\n",
    "test_ds = pd.read_csv(\"val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqlcD7x6Yjcd"
   },
   "outputs": [],
   "source": [
    "def class_labels(age):\n",
    "\n",
    "    if  age == 0:\n",
    "        return 0\n",
    "    elif  age == 1:\n",
    "        return 0\n",
    "    elif  age == 2:\n",
    "        return 1\n",
    "    elif  age == 3:\n",
    "        return 1\n",
    "    elif  age == 4:\n",
    "        return 2\n",
    "    elif age == 5:\n",
    "        return 2\n",
    "    elif  age == 6:\n",
    "        return 3\n",
    "    elif  age == 7:\n",
    "        return 3\n",
    "    elif  age == 8:\n",
    "        return 4\n",
    "    elif  age == 9:\n",
    "        return 4\n",
    "    elif  age == 10:\n",
    "        return 5\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LROsGcIaYjVr"
   },
   "outputs": [],
   "source": [
    "train_ds['target'] = train_ds['age'].map(class_labels)\n",
    "test_ds['target'] = test_ds['age'].map(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1316,
     "status": "ok",
     "timestamp": 1592789471687,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "jWpwyHjzYjQN",
    "outputId": "d2ef2f1b-4ad2-4151-8354-d96167be93ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.169275\n",
       "4    0.169028\n",
       "5    0.168905\n",
       "0    0.166312\n",
       "3    0.165174\n",
       "1    0.161306\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1592789471689,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "KUS5oAuRavFJ",
    "outputId": "98e44551-6e66-4907-8874-4218ac00a981"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2468\n",
       "4    2460\n",
       "5    2442\n",
       "3    2406\n",
       "0    2388\n",
       "1    2282\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['target'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJSY34ShavL_"
   },
   "outputs": [],
   "source": [
    "# Converting the filenames and target class labels into lists for augmented train and test datasets.\n",
    "\n",
    "train_path = list(train_ds['filename'])\n",
    "train_ll = list(train_ds['target'])\n",
    "\n",
    "test_path = list(test_ds['filename'])\n",
    "test_ll = list(test_ds['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7ye8s5savP5"
   },
   "outputs": [],
   "source": [
    "# Creating tensorflow constants of filenames and labels for augmented train and test datasets from the lists defined above.\n",
    "\n",
    "train_path_tf = tf.constant(train_path)\n",
    "train_ll_tf = tf.constant(train_ll)\n",
    "\n",
    "test_path_tf = tf.constant(test_path)\n",
    "test_ll_tf = tf.constant(test_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ALPko3Xavbo"
   },
   "outputs": [],
   "source": [
    "# Defining a function to read the image, decode the image from given tensor and one-hot encode the image label class.\n",
    "# Changing the channels para in tf.io.decode_jpeg from 3 to 1 changes the output images from RGB coloured to grayscale.\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    \n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.io.decode_jpeg(image_string, channels=1)    # channels=1 to convert to grayscale, channels=3 to convert to RGB.\n",
    "    # image_resized = tf.image.resize(image_decoded, [200, 200])\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    print(image_decoded)\n",
    "\n",
    "    return image_decoded, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTyXZ2tUavZh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"DecodeJpeg:0\", shape=(None, None, 1), dtype=uint8)\n",
      "Tensor(\"DecodeJpeg:0\", shape=(None, None, 1), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "# Getting the dataset ready for the neural network.\n",
    "# Using the tensor vectors defined above, accessing the images in the dataset and passing them through the function defined above.\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_path_tf, train_ll_tf))\n",
    "train_dataset = train_dataset.map(_parse_function)\n",
    "\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_path_tf, test_ll_tf))\n",
    "test_dataset = test_dataset.map(_parse_function)\n",
    "\n",
    "test_dataset = test_dataset.batch(32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 961,
     "status": "ok",
     "timestamp": 1592794444041,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "kcW44JspavWb",
    "outputId": "71eb87a3-703c-4a2a-e06b-e5f141929662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 196, 196, 32)      832       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 65, 65, 32)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 128)       102528    \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 30, 30, 128)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 14, 14, 256)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 6, 6, 256)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 192)         442560    \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 2, 2, 192)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 192)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               98816     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 132)               67716     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 798       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,598,498\n",
      "Trainable params: 1,598,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_cnn_arh = Sequential()\n",
    "\n",
    "my_cnn_arh.add(Conv2D(filters=32, kernel_size=5, activation='relu', input_shape=(200, 200, 1)))\n",
    "my_cnn_arh.add(AveragePooling2D(pool_size=(3,3)))\n",
    "\n",
    "my_cnn_arh.add(Conv2D(filters=128, kernel_size=5, activation='relu'))\n",
    "my_cnn_arh.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "my_cnn_arh.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "my_cnn_arh.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "my_cnn_arh.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "my_cnn_arh.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "my_cnn_arh.add(Conv2D(filters=192, kernel_size=3, activation='relu'))\n",
    "my_cnn_arh.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "my_cnn_arh.add(GlobalAveragePooling2D())\n",
    "\n",
    "my_cnn_arh.add(Dense(512, activation='relu'))\n",
    "my_cnn_arh.add(Dense(132, activation='relu'))\n",
    "\n",
    "my_cnn_arh.add(Dense(6, activation='softmax'))\n",
    "\n",
    "my_cnn_arh.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBG5MY8zavTn"
   },
   "outputs": [],
   "source": [
    "my_cnn_arh.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6dQDDhmfuzo"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'save/weight.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy',save_best_only=True,save_weights_only=False,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1362636,
     "status": "ok",
     "timestamp": 1592803783361,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "hU4LJT6xYjJp",
    "outputId": "0ab09013-5d21-44d3-a728-d4bf3c8bcab9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_cnn_arh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m my_cnn_arh_history \u001b[38;5;241m=\u001b[39m \u001b[43mmy_cnn_arh\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_dataset,validation_data\u001b[38;5;241m=\u001b[39mtest_dataset,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,callbacks\u001b[38;5;241m=\u001b[39m[tensorboard, checkpoint],shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_cnn_arh' is not defined"
     ]
    }
   ],
   "source": [
    "my_cnn_arh_history = my_cnn_arh.fit(train_dataset,validation_data=test_dataset,batch_size=32,epochs=1,callbacks=[tensorboard, checkpoint],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RP7vxY_6YjCM"
   },
   "outputs": [],
   "source": [
    "train_loss = my_cnn_arh_history.history['loss']\n",
    "test_loss = my_cnn_arh_history.history['val_loss']\n",
    "train_accuracy = my_cnn_arh_history.history['accuracy']\n",
    "test_accuracy = my_cnn_arh_history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2083,
     "status": "ok",
     "timestamp": 1592806180903,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "COkki9JUU8kf",
    "outputId": "c4217a95-784c-42e6-c052-7c4f0e4aa447"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(15,7))\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "ax[0].plot(train_loss, label='Train Loss', color='royalblue', marker='o', markersize=5)\n",
    "ax[0].plot(test_loss, label='Test Loss', color = 'orangered', marker='o', markersize=5)\n",
    "\n",
    "ax[0].set_xlabel('Epochs', fontsize=14)\n",
    "ax[0].set_ylabel('Categorical Crossentropy', fontsize=14)\n",
    "\n",
    "ax[0].legend(fontsize=14)\n",
    "ax[0].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "ax[1].plot(train_accuracy, label='Train Accuracy', color='royalblue', marker='o', markersize=5)\n",
    "ax[1].plot(test_accuracy, label='Test Accuracy', color='orangered', marker='o', markersize=5)\n",
    "\n",
    "ax[1].set_xlabel('Epochs', fontsize=14)\n",
    "ax[1].set_ylabel('Accuracy', fontsize=14)\n",
    "\n",
    "ax[1].legend(fontsize=14)\n",
    "ax[1].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "fig.suptitle(x=0.5, y=0.92, t=\"Линейные графики, показывающие потери и точность модели CNN по эпохам\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5596,
     "status": "ok",
     "timestamp": 1592806219385,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "F75NJtVJU8oD",
    "outputId": "50e05ca0-4673-4f29-e2b2-f348504c73a8"
   },
   "outputs": [],
   "source": [
    "final_cnn_score = final_cnn.evaluate(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2328,
     "status": "ok",
     "timestamp": 1592806219389,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "h5JdZYFMU8s0",
    "outputId": "dd98d3e6-58a9-46cb-f676-be4ad91fe5c2"
   },
   "outputs": [],
   "source": [
    "# Printing the relevant score summary.\n",
    "\n",
    "final_cnn_labels = final_cnn.metrics_names\n",
    "print(f'CNN model {final_cnn_labels[0]} \\t\\t= {round(final_cnn_score[0], 3)}')\n",
    "print(f'CNN model {final_cnn_labels[1]} \\t= {round(final_cnn_score[1], 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fatkGFAkrjCF"
   },
   "outputs": [],
   "source": [
    "final_cnn.save(f\"save/final_cnn_model_acc_{round(final_cnn_score[1], 3)}.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1e1uYqHU8wx"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = load_model(\"save/weight.h5\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    faces = face_cascade.detectMultiScale(img, scaleFactor=1.2, minNeighbors=6, minSize=(100, 100))\n",
    "\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        \n",
    "        img2 = img[y:y+h, x:x+w]\n",
    "        img_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray = cv2.resize(img_gray, (200, 200))\n",
    "        img_gray = img_gray.reshape(-1, 200, 200, 1)\n",
    "\n",
    "        prediction = model.predict(img_gray)\n",
    "        # age_ranges = ['1-3', '4-8', '9-13', '14-17', '18-21', '22-24', '25-27', '28-30', '31-35', '36-40', '41-45', '46-50']\n",
    "        age_ranges = ['1-8', '9-17', '18-24', '25-30', '31-40', '41-50']\n",
    "        v = np.argmax(prediction[0])\n",
    "\n",
    "        face_rect = cv2.rectangle(img, (x, y), (x+w, y+h), (0, 100, 0), thickness=2)\n",
    "        face_rect = cv2.rectangle(img, (x-1, y), (x+w+1, y-50),(0, 100, 0),thickness=-1)\n",
    "        \n",
    "        ag_text = str(age_ranges[v])+' лет'\n",
    "        ag_text2 ='('+str(prediction[0][v])+')'\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        pos = (x,y-25)\n",
    "        pos2 = (x,y-5)\n",
    "        fontScale = 0.6\n",
    "        fontColor = (255,255,255)\n",
    "        thickness = 1\n",
    "        lineType = 2\n",
    "        \n",
    "        cv2.putText(img,ag_text, \n",
    "            pos, \n",
    "            font, \n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            thickness,\n",
    "            lineType)\n",
    "        \n",
    "        cv2.putText(img,ag_text2, \n",
    "            pos2, \n",
    "            font, \n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            thickness,\n",
    "            lineType)\n",
    "        \n",
    "    cv2.imshow(\"camera\", img)\n",
    "    if cv2.waitKey(10) == 27: # Клавиша Esc\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1e1uYqHU8wx"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"test/tests.jpg\")  \n",
    "model = load_model(\"save/weight.h5\")\n",
    "\n",
    "detector = MTCNN() # создание детектора\n",
    "result = detector.detect_faces(img)\n",
    "\n",
    "# for i in range(len(result)): \n",
    "#     bounding_box = result[i]['box']  #  ограничивающие рамки\n",
    "#     cv2.rectangle(img, (bounding_box[0], bounding_box[1]),\n",
    "#     (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "#            (0,155,255), 2) #  ограничение области на изображении\n",
    "#     plt.imshow(image)\n",
    "# plt.imshow(image)\n",
    "# face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "# faces = face_cascade.detectMultiScale(img, scaleFactor=1.2, minNeighbors=6, minSize=(100, 100))\n",
    "for i in range(len(result)):\n",
    "        bounding_box = result[i]['box']\n",
    "        img2 = img[bounding_box[1]:bounding_box[1]+bounding_box[3], bounding_box[0]:bounding_box[0]+bounding_box[2]]\n",
    "        img_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray = cv2.resize(img_gray, (200, 200))\n",
    "        img_gray = img_gray.reshape(-1, 200, 200, 1)\n",
    "\n",
    "        prediction = model.predict(img_gray)\n",
    "        # age_ranges = ['1-3', '4-8', '9-13', '14-17', '18-21', '22-24', '25-27', '28-30', '31-35', '36-40', '41-45', '46-50']\n",
    "        age_ranges = ['1-8', '9-17', '18-24', '25-30', '31-40', '41-50']\n",
    "        v = np.argmax(prediction[0])\n",
    "\n",
    "        cv2.rectangle(img, (bounding_box[0], bounding_box[1]), (bounding_box[0]+bounding_box[2], bounding_box[1]+bounding_box[3]), (0, 100, 0), 2)\n",
    "        cv2.rectangle(img, (bounding_box[0]- 1, bounding_box[1]), (bounding_box[0]+bounding_box[2]+1, bounding_box[1]-50),(0, 100, 0),-1)\n",
    "        \n",
    "        ag_text = str(age_ranges[v])+' лет'\n",
    "        # ag_text2 ='('+str(prediction[0][v])+')'\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        pos = (bounding_box[0],bounding_box[1]-25)\n",
    "        pos2 = (bounding_box[0],bounding_box[1]-5)\n",
    "        fontScale = 0.6\n",
    "        fontColor = (255,255,255)\n",
    "        thickness = 1\n",
    "        lineType = 2\n",
    "        \n",
    "        cv2.putText(img,ag_text, \n",
    "            pos, \n",
    "            font, \n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            thickness,\n",
    "            lineType)\n",
    "        \n",
    "        # cv2.putText(img,ag_text2, \n",
    "        #     pos2, \n",
    "        #     font, \n",
    "        #     fontScale,\n",
    "        #     fontColor,\n",
    "        #     thickness,\n",
    "        #     lineType)\n",
    "        \n",
    "cv2.imshow(\"fhoto\", img)\n",
    "cv2.waitKey(55000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1e1uYqHU8wx"
   },
   "outputs": [],
   "source": [
    "\n",
    "final_cnn_pred = final_cnn.predict(test_dataset)\n",
    "final_cnn_pred = final_cnn_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3107,
     "status": "ok",
     "timestamp": 1592806228201,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "aYLmUsxcU85i",
    "outputId": "920af7b3-1ced-4cfd-c698-1a1f875d176f"
   },
   "outputs": [],
   "source": [
    "len(test_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1780,
     "status": "ok",
     "timestamp": 1592806236230,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "T6hAs7SlU9Zi",
    "outputId": "b1bf5e75-225d-478d-b171-adee57e827f7"
   },
   "outputs": [],
   "source": [
    "# Generating a confusion matrix based on above predictions.\n",
    "\n",
    "conf_mat = confusion_matrix(test_labels_list, final_cnn_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uACH8n6fU95F"
   },
   "outputs": [],
   "source": [
    "# Defining a function to plot the confusion matrix in a grid for easier visualization.\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', export_as='confusion_matrix', cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Реальный возраст', fontsize=14)\n",
    "    plt.xlabel('Предсказанный возраст', fontsize=14)\n",
    "\n",
    "    # plt.savefig(f'/content/drive/My Drive/Age_Classification_with_Faces/plot_images/{export_as}.png', bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2183,
     "status": "ok",
     "timestamp": 1592806243323,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "J1XROLD_U91Z",
    "outputId": "5f3515d0-b968-4360-82dc-8566d18b6bcf"
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix using the function defined above.\n",
    "\n",
    "cm_plot_labels = ['1-8', '9-17', '18-24', '25-30', '31-40', '41-50']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plot_confusion_matrix(conf_mat, cm_plot_labels, normalize=True,\n",
    "                      title=\"Матрица ошибок основанная на предсказаниях модели CNN\",\n",
    "                      export_as=\"final_cnn_conf_mat_norm\"\n",
    "                     )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1828,
     "status": "ok",
     "timestamp": 1592806254827,
     "user": {
      "displayName": "Prerak Agarwal",
      "photoUrl": "",
      "userId": "01206615471624868818"
     },
     "user_tz": -480
    },
    "id": "b8SX7GwcU9vz",
    "outputId": "47807da8-fddb-4753-e465-cc4d08d99d96"
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix using the function defined above.\n",
    "\n",
    "cm_plot_labels = ['1-8', '9-17', '18-24', '25-30', '31-40', '41-50']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plot_confusion_matrix(conf_mat, cm_plot_labels, normalize=False,\n",
    "                      title=\"Матрица ошибок основанная на предсказаниях модели CNN\",\n",
    "                      export_as=\"final_cnn_conf_mat\"\n",
    "                     )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_classes(ser, n_classes):\n",
    "\n",
    "    # Calculating the target number of images per class depending on the total no. of images in the dataset.\n",
    "    n_images = int(sum(ser) / n_classes)\n",
    "\n",
    "    print(f\"Total no. of images in dataset\\t= {sum(ser)}\")\n",
    "    print(f\"No. of classes desired\\t\\t= {n_classes}\")\n",
    "    print(f\"So, target no. of images/class\\t>= {sum(ser)}/{n_classes} = ~{n_images}\")\n",
    "    print()\n",
    "\n",
    "    # Initiating a dataframe to show the breakdown of age-ranges as output.\n",
    "    classes_df = pd.DataFrame(columns=['Age-ranges (classes)', 'No. of images', 'Class balance (%)'])\n",
    "\n",
    "    # Initiating an age index variable to be used to iterate through the ages in the given input series.\n",
    "    age_index = 0\n",
    "\n",
    "    for i in range(n_classes):\n",
    "\n",
    "        # Storing the starting age of the class in a variable age_start.\n",
    "        # Storing the current age being iterated in a variable age_current.\n",
    "        # Keeping track of age_index variable so as not to let it go out of index.\n",
    "        if age_index<=103:\n",
    "            age_start = ser.index[age_index]\n",
    "            age_current = ser.index[age_index]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        # Initiating a new variable to keep track of no. of images added to current class.\n",
    "        class_images = 0\n",
    "        \n",
    "        # Iterating through the ages in the given input series and adding up the no. of images\n",
    "        # until it exceeds the target number of images per class, using the age_index and age_current variables.\n",
    "        while class_images < n_images:\n",
    "            class_images += ser[age_current]\n",
    "            age_index += 1\n",
    "\n",
    "            # Keeping track of age_index variable so as not to let it go out of index.\n",
    "            if age_index<=103:\n",
    "                age_current = ser.index[age_index]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Storing the ending age of the class in a variable age_end.\n",
    "        # Keeping track of age_index variable so as not to let it go out of index.\n",
    "        if age_index<=104:\n",
    "            age_end = ser.index[age_index-1]\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # Adding the above calculated variables into the dataframe for easier printing and analysis.\n",
    "        classes_df.loc[i, 'Age-ranges (classes)'] = str(age_start)+\" - \"+str(age_end)\n",
    "        classes_df.loc[i, 'No. of images'] = class_images\n",
    "        classes_df.loc[i, 'Class balance (%)'] = round((class_images / sum(ser)) * 100, 2)\n",
    "    \n",
    "    # Calculating some basic statistics about no. of images and the class balance.\n",
    "    mean_images = int(round(np.mean(classes_df.loc[:, 'No. of images'])))\n",
    "    mean_balance = round(np.mean(classes_df.loc[:, 'Class balance (%)']), 2)\n",
    "    std_balance = round(np.std(classes_df.loc[:, 'Class balance (%)']), 2)\n",
    "    \n",
    "    print(f\"Mean no. of images/class\\t= ~{mean_images}\")\n",
    "    print(f\"Mean class balance\\t\\t= {mean_balance}%\")\n",
    "    print(f\"Std. of class balance\\t\\t= {std_balance}%\")\n",
    "    print()\n",
    "\n",
    "    # Returning the dataframe with all the classes info.\n",
    "    return classes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facial_age_classes = split_classes(train_aug_df['target'], 6)\n",
    "facial_age_classes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model: \"sequential_4\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d_20 (Conv2D)          (None, 196, 196, 32)      832       \n",
    "                                                                 \n",
    " average_pooling2d_20 (Avera  (None, 65, 65, 32)       0         \n",
    " gePooling2D)                                                    \n",
    "                                                                 \n",
    " conv2d_21 (Conv2D)          (None, 61, 61, 128)       102528    \n",
    "                                                                 \n",
    " average_pooling2d_21 (Avera  (None, 30, 30, 128)      0         \n",
    " gePooling2D)                                                    \n",
    "                                                                 \n",
    " conv2d_22 (Conv2D)          (None, 28, 28, 256)       295168    \n",
    "                                                                 \n",
    " average_pooling2d_22 (Avera  (None, 14, 14, 256)      0         \n",
    " gePooling2D)                                                    \n",
    "                                                                 \n",
    " conv2d_23 (Conv2D)          (None, 12, 12, 256)       590080    \n",
    "                                                                 \n",
    " average_pooling2d_23 (Avera  (None, 6, 6, 256)        0         \n",
    " gePooling2D)                                                    \n",
    "                                                                 \n",
    " conv2d_24 (Conv2D)          (None, 4, 4, 192)         442560    \n",
    "                                                                 \n",
    " average_pooling2d_24 (Avera  (None, 2, 2, 192)        0         \n",
    " gePooling2D)                                                    \n",
    "                                                                 \n",
    " global_average_pooling2d_2   (None, 192)              0         \n",
    " (GlobalAveragePooling2D)                                        \n",
    "                                                                 \n",
    " dense_6 (Dense)             (None, 512)               98816     \n",
    "                                                                 \n",
    " dense_7 (Dense)             (None, 132)               67716     \n",
    "                                                                 \n",
    " dense_8 (Dense)             (None, 6)                 798       \n",
    "                                                                 \n",
    "    \n",
    "=================================================================\n",
    "Total params: 1,598,498\n",
    "Trainable params: 1,598,498\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import *\n",
    "import tkinter.filedialog as fd\n",
    "import cv2\n",
    "from PIL import Image,ImageTk\n",
    "\n",
    "root = Tk()\n",
    "fix_h = 550\n",
    "kh = 0\n",
    "model = load_model(\"save/weight.h5\")\n",
    "def choose_file():\n",
    "    \n",
    "        filetypes = ((\"Изображение\", \"*.jpg *.gif *.png\"),\n",
    "                     (\"Любой\", \"*\"))\n",
    "        filename = fd.askopenfilename(title=\"Открыть файл\", initialdir=\"/\",\n",
    "                                      filetypes=filetypes)\n",
    "        if filename:\n",
    "            \n",
    "            for widget in frame2.winfo_children():\n",
    "                widget.destroy()\n",
    "                \n",
    "            img = cv2.imread(filename)  \n",
    "\n",
    "            detector = MTCNN()\n",
    "            result = detector.detect_faces(img)\n",
    "            text_age = \"\"\n",
    "            \n",
    "            for i in range(len(result)):\n",
    "                \n",
    "                bounding_box = result[i]['box']\n",
    "                img2 = img[bounding_box[1]:bounding_box[1]+bounding_box[3], bounding_box[0]:bounding_box[0]+bounding_box[2]]\n",
    "                img_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "                img_gray = cv2.resize(img_gray, (200, 200))\n",
    "                img_gray = img_gray.reshape(-1, 200, 200, 1)\n",
    "\n",
    "                prediction = model.predict(img_gray)\n",
    "                age_ranges = ['1-8', '9-17', '18-24', '25-30', '31-40', '41-50']\n",
    "                v = np.argmax(prediction[0])\n",
    "\n",
    "                cv2.rectangle(img, (bounding_box[0], bounding_box[1]), (bounding_box[0]+bounding_box[2], bounding_box[1]+bounding_box[3]), (0, 100, 0), 2)\n",
    "                cv2.rectangle(img, (bounding_box[0]- 1, bounding_box[1]), (bounding_box[0]+bounding_box[2]+1, bounding_box[1]-50),(0, 100, 0),-1)\n",
    "\n",
    "                ag_text = str(i+1)+': '+str(age_ranges[v])\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_COMPLEX\n",
    "                pos = (bounding_box[0],bounding_box[1]-25)\n",
    "                pos2 = (bounding_box[0],bounding_box[1]-5)\n",
    "                fontScale = 0.8\n",
    "                fontColor = (255,255,255)\n",
    "                thickness = 1\n",
    "                lineType = 2\n",
    "                \n",
    "                text_age += \"Возраст \"+str(i+1)+\" человека \"+str(age_ranges[v])+' лет.'\n",
    "\n",
    "                cv2.putText(img,ag_text, \n",
    "                    pos, \n",
    "                    font, \n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    thickness,\n",
    "                    lineType)\n",
    "            \n",
    "            b,g,r = cv2.split(img)\n",
    "            imgr = cv2.merge((r,g,b))\n",
    "            im = Image.fromarray(imgr)\n",
    "            \n",
    "            height_percent = (fix_h / float(im.size[1]))\n",
    "            width_size = int((float(im.size[0]) * float(height_percent)))\n",
    "            new_image = im.resize((width_size, fix_h))\n",
    "            imaget = ImageTk.PhotoImage(new_image)\n",
    "            \n",
    "            lb = Label(frame2,\n",
    "                        height =fix_h,\n",
    "                        image=imaget)\n",
    "            lb.imaget = imaget\n",
    "            lb.pack(padx=30)\n",
    "            \n",
    "            lb2 = Label(frame3,\n",
    "                        font=\"Arial 22\",\n",
    "                        wraplength=1000,\n",
    "                        justify=LEFT,\n",
    "                        foreground=\"#ffffff\",\n",
    "                        background=\"#767676\",\n",
    "                        text=\"На фото было найдено \"+str(len(result))+\" человек(а).\\n\"+text_age,\n",
    "                        )\n",
    "            lb2.pack(side=LEFT, anchor=N, )\n",
    "               \n",
    "                \n",
    "def web_cam(): \n",
    "    for widget in frame2.winfo_children():\n",
    "                widget.destroy()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 600)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 500)\n",
    "    lb = Label(frame2)\n",
    "    root.bind('q', lambda e: quit())\n",
    "    lb.pack()\n",
    "    detector = MTCNN()\n",
    "    def web_cam_loop():\n",
    "        _, img = cap.read()\n",
    "        img = cv2.flip(img, 1)\n",
    "        result = detector.detect_faces(img)\n",
    "\n",
    "        for i in range(len(result)):\n",
    "\n",
    "            bounding_box = result[i]['box']\n",
    "            img2 = img[bounding_box[1]:bounding_box[1]+bounding_box[3], bounding_box[0]:bounding_box[0]+bounding_box[2]]\n",
    "            img_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "            img_gray = cv2.resize(img_gray, (200, 200))\n",
    "            img_gray = img_gray.reshape(-1, 200, 200, 1)\n",
    "\n",
    "            prediction = model.predict(img_gray)\n",
    "            age_ranges = ['1-8', '9-17', '18-24', '25-30', '31-40', '41-50']\n",
    "            v = np.argmax(prediction[0])\n",
    "\n",
    "            cv2.rectangle(img, (bounding_box[0], bounding_box[1]), (bounding_box[0]+bounding_box[2], bounding_box[1]+bounding_box[3]), (0, 100, 0), 2)\n",
    "            cv2.rectangle(img, (bounding_box[0]- 1, bounding_box[1]), (bounding_box[0]+bounding_box[2]+1, bounding_box[1]-50),(0, 100, 0),-1)\n",
    "\n",
    "            ag_text = str(age_ranges[v])+\" лет\"\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_COMPLEX\n",
    "            pos = (bounding_box[0],bounding_box[1]-25)\n",
    "            pos2 = (bounding_box[0],bounding_box[1]-5)\n",
    "            fontScale = 0.8\n",
    "            fontColor = (255,255,255)\n",
    "            thickness = 1\n",
    "            lineType = 2\n",
    "\n",
    "            cv2.putText(img,ag_text, \n",
    "                            pos, \n",
    "                            font, \n",
    "                            fontScale,\n",
    "                            fontColor,\n",
    "                            thickness,\n",
    "                            lineType)\n",
    "\n",
    "            cv2image = cv2.cvtColor(img, cv2.COLOR_BGR2RGBA)\n",
    "            im = Image.fromarray(cv2image)\n",
    "            imaget = ImageTk.PhotoImage(im)\n",
    "            lb.imaget = imaget\n",
    "            lb.configure(image=imaget)\n",
    "            lb.after(10,web_cam_loop)\n",
    "    web_cam_loop()\n",
    "\n",
    "            \n",
    "root['bg'] = '#fafafa'\n",
    "root.title('Приложение для определения возраста')\n",
    "root.geometry('1200x700')\n",
    "\n",
    "frame1 = Frame(root,bg='#989898',bd=5)\n",
    "frame1.place(relx=0,rely=0,relwidth=0.20,relheight=1)\n",
    "\n",
    "frame2 = Frame(root,bg='#555555',bd=5)\n",
    "frame2.place(relx=0.20,rely=0,relwidth=0.80,relheight=1)\n",
    "\n",
    "frame3 = Frame(root,bg='#767676',bd=5)\n",
    "frame3.place(relx=0.20,rely=0.8,relwidth=0.80,relheight=1)\n",
    "\n",
    "btn = Button(frame1,\n",
    "             text='Выбрать фото',\n",
    "             width = 500,\n",
    "             height = 3,\n",
    "             background=\"#555\",\n",
    "             foreground=\"#ffffff\",\n",
    "             command=choose_file)\n",
    "btn.pack(padx=10, pady=10)\n",
    "btn2 = Button(frame1,\n",
    "             text='Видеокамера',\n",
    "             width = 500,\n",
    "             height = 3,\n",
    "             background=\"#555\",\n",
    "             foreground=\"#ffffff\",\n",
    "             command=web_cam)\n",
    "btn2.pack(padx=10, pady=10)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "width, height = 800, 600\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.bind('<Escape>', lambda e: root.quit())\n",
    "lmain = tk.Label(root)\n",
    "lmain.pack()\n",
    "def show_frame():\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(img)\n",
    "    lmain.imgtk = imgtk\n",
    "    lmain.configure(image=imgtk)\n",
    "\n",
    "\n",
    "\n",
    "show_frame()\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNxnQ0Ee0XR29vi5j4qvL9F",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "5_deep_learning_final_CNN_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
